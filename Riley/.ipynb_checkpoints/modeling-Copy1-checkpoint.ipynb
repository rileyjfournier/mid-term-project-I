{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "In this file, instructions how to approach the challenge can be found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to work on different types of Machine Learning problems:\n",
    "\n",
    "- **Regression Problem**: The goal is to predict delay of flights.\n",
    "- **(Stretch) Multiclass Classification**: If the plane was delayed, we will predict what type of delay it is (will be).\n",
    "- **(Stretch) Binary Classification**: The goal is to predict if the flight will be cancelled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Task: Regression Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variable is **ARR_DELAY**. We need to be careful which columns to use and which don't. For example, DEP_DELAY is going to be the perfect predictor, but we can't use it because in real-life scenario, we want to predict the delay before the flight takes of --> We can use average delay from earlier days but not the one from the actual flight we predict.  \n",
    "\n",
    "For example, variables **CARRIER_DELAY, WEATHER_DELAY, NAS_DELAY, SECURITY_DELAY, LATE_AIRCRAFT_DELAY** shouldn't be used directly as predictors as well. However, we can create various transformations from earlier values.\n",
    "\n",
    "We will be evaluating your models by predicting the ARR_DELAY for all flights **1 week in advance**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Base DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bring in testing data\n",
    "test_df = pd.read_csv('../DB/test_sample.csv', index_col='Unnamed: 0')\n",
    "test_df = test_df.dropna()\n",
    "\n",
    "# bring in flights data\n",
    "flights_df = pd.read_csv('../DB/flights_data.csv', index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find testing data features\n",
    "feature_cols = list(test_df.columns)\n",
    "feature_cols.append('arr_delay')\n",
    "\n",
    "# create base training features from existing testing features\n",
    "X = flights_df[feature_cols]\n",
    "X = feature_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find numeric and categorical features\n",
    "cols = X.columns\n",
    "num_cols = X._get_numeric_data().columns\n",
    "cat_cols = list(set(cols) - set(num_cols))\n",
    "\n",
    "# remove redundant numeric columns\n",
    "final_num_cols = list(num_cols)\n",
    "final_num_cols.remove('op_carrier_fl_num')\n",
    "final_num_cols.remove('flights')\n",
    "\n",
    "# remove redundant categorical columns\n",
    "final_cat_cols = ['mkt_unique_carrier', 'fl_date', 'tail_num', 'branded_code_share']\n",
    "\n",
    "# combine final features\n",
    "final_features = final_num_cols + final_cat_cols\n",
    "\n",
    "X = X[final_features]\n",
    "\n",
    "# convert fl_date feature into datetime\n",
    "X['fl_date'] = pd.to_datetime(X['fl_date'])\n",
    "\n",
    "# separate datetime into date features\n",
    "X['year'] = X['fl_date'].dt.year\n",
    "X['month'] = X['fl_date'].dt.month\n",
    "X['week'] = X['fl_date'].dt.isocalendar().week\n",
    "X['day'] = X['fl_date'].dt.day\n",
    "X['day_of_week'] = X['fl_date'].dt.dayofweek\n",
    "\n",
    "# reset index for collaborative data sorting structure\n",
    "X = X.reset_index()\n",
    "X.index.name = 'order'\n",
    "X = X.drop(columns=['index'])\n",
    "\n",
    "# set y\n",
    "y = X[['arr_delay']]\n",
    "\n",
    "# drop original fl_date and arr_delay columns\n",
    "X = X.drop(columns=['fl_date'])\n",
    "X = X.drop(columns=['arr_delay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mkt_carrier_fl_num</th>\n",
       "      <th>origin_airport_id</th>\n",
       "      <th>dest_airport_id</th>\n",
       "      <th>crs_dep_time</th>\n",
       "      <th>crs_arr_time</th>\n",
       "      <th>crs_elapsed_time</th>\n",
       "      <th>distance</th>\n",
       "      <th>mkt_unique_carrier</th>\n",
       "      <th>tail_num</th>\n",
       "      <th>branded_code_share</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>week</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_week</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>order</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3501</td>\n",
       "      <td>12953</td>\n",
       "      <td>13930</td>\n",
       "      <td>1300</td>\n",
       "      <td>1444</td>\n",
       "      <td>164.0</td>\n",
       "      <td>733.0</td>\n",
       "      <td>UA</td>\n",
       "      <td>N744YX</td>\n",
       "      <td>UA_CODESHARE</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3502</td>\n",
       "      <td>11433</td>\n",
       "      <td>12266</td>\n",
       "      <td>630</td>\n",
       "      <td>854</td>\n",
       "      <td>204.0</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>UA</td>\n",
       "      <td>N640RW</td>\n",
       "      <td>UA_CODESHARE</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3503</td>\n",
       "      <td>11618</td>\n",
       "      <td>11433</td>\n",
       "      <td>1500</td>\n",
       "      <td>1709</td>\n",
       "      <td>129.0</td>\n",
       "      <td>488.0</td>\n",
       "      <td>UA</td>\n",
       "      <td>N641RW</td>\n",
       "      <td>UA_CODESHARE</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3504</td>\n",
       "      <td>11618</td>\n",
       "      <td>11278</td>\n",
       "      <td>2041</td>\n",
       "      <td>2159</td>\n",
       "      <td>78.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>UA</td>\n",
       "      <td>N722YX</td>\n",
       "      <td>UA_CODESHARE</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3505</td>\n",
       "      <td>12266</td>\n",
       "      <td>11298</td>\n",
       "      <td>2140</td>\n",
       "      <td>2257</td>\n",
       "      <td>77.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>UA</td>\n",
       "      <td>N855RW</td>\n",
       "      <td>UA_CODESHARE</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161997</th>\n",
       "      <td>2789</td>\n",
       "      <td>13487</td>\n",
       "      <td>14771</td>\n",
       "      <td>925</td>\n",
       "      <td>1143</td>\n",
       "      <td>258.0</td>\n",
       "      <td>1589.0</td>\n",
       "      <td>DL</td>\n",
       "      <td>N886DN</td>\n",
       "      <td>DL</td>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161998</th>\n",
       "      <td>2790</td>\n",
       "      <td>10721</td>\n",
       "      <td>13487</td>\n",
       "      <td>1841</td>\n",
       "      <td>2101</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>DL</td>\n",
       "      <td>N302DN</td>\n",
       "      <td>DL</td>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161999</th>\n",
       "      <td>2791</td>\n",
       "      <td>10397</td>\n",
       "      <td>11298</td>\n",
       "      <td>1000</td>\n",
       "      <td>1116</td>\n",
       "      <td>136.0</td>\n",
       "      <td>731.0</td>\n",
       "      <td>DL</td>\n",
       "      <td>N375NC</td>\n",
       "      <td>DL</td>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162000</th>\n",
       "      <td>2791</td>\n",
       "      <td>11298</td>\n",
       "      <td>10397</td>\n",
       "      <td>1201</td>\n",
       "      <td>1512</td>\n",
       "      <td>131.0</td>\n",
       "      <td>731.0</td>\n",
       "      <td>DL</td>\n",
       "      <td>N375NC</td>\n",
       "      <td>DL</td>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162001</th>\n",
       "      <td>2793</td>\n",
       "      <td>12889</td>\n",
       "      <td>14747</td>\n",
       "      <td>1855</td>\n",
       "      <td>2132</td>\n",
       "      <td>157.0</td>\n",
       "      <td>867.0</td>\n",
       "      <td>DL</td>\n",
       "      <td>N3756</td>\n",
       "      <td>DL</td>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162002 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        mkt_carrier_fl_num  origin_airport_id  dest_airport_id  crs_dep_time  \\\n",
       "order                                                                          \n",
       "0                     3501              12953            13930          1300   \n",
       "1                     3502              11433            12266           630   \n",
       "2                     3503              11618            11433          1500   \n",
       "3                     3504              11618            11278          2041   \n",
       "4                     3505              12266            11298          2140   \n",
       "...                    ...                ...              ...           ...   \n",
       "161997                2789              13487            14771           925   \n",
       "161998                2790              10721            13487          1841   \n",
       "161999                2791              10397            11298          1000   \n",
       "162000                2791              11298            10397          1201   \n",
       "162001                2793              12889            14747          1855   \n",
       "\n",
       "        crs_arr_time  crs_elapsed_time  distance mkt_unique_carrier tail_num  \\\n",
       "order                                                                          \n",
       "0               1444             164.0     733.0                 UA   N744YX   \n",
       "1                854             204.0    1075.0                 UA   N640RW   \n",
       "2               1709             129.0     488.0                 UA   N641RW   \n",
       "3               2159              78.0     199.0                 UA   N722YX   \n",
       "4               2257              77.0     224.0                 UA   N855RW   \n",
       "...              ...               ...       ...                ...      ...   \n",
       "161997          1143             258.0    1589.0                 DL   N886DN   \n",
       "161998          2101             200.0    1124.0                 DL   N302DN   \n",
       "161999          1116             136.0     731.0                 DL   N375NC   \n",
       "162000          1512             131.0     731.0                 DL   N375NC   \n",
       "162001          2132             157.0     867.0                 DL    N3756   \n",
       "\n",
       "       branded_code_share  year  month  week  day  day_of_week  \n",
       "order                                                           \n",
       "0            UA_CODESHARE  2018      1     1    1            0  \n",
       "1            UA_CODESHARE  2018      1     1    1            0  \n",
       "2            UA_CODESHARE  2018      1     1    1            0  \n",
       "3            UA_CODESHARE  2018      1     1    1            0  \n",
       "4            UA_CODESHARE  2018      1     1    1            0  \n",
       "...                   ...   ...    ...   ...  ...          ...  \n",
       "161997                 DL  2019      7    31   31            2  \n",
       "161998                 DL  2019      7    31   31            2  \n",
       "161999                 DL  2019      7    31   31            2  \n",
       "162000                 DL  2019      7    31   31            2  \n",
       "162001                 DL  2019      7    31   31            2  \n",
       "\n",
       "[162002 rows x 15 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Monthly Passenger Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store passengers csv from DB folder into a DataFrame\n",
    "pas_df = pd.read_csv('../DB/passengers_data.csv', index_col='Unnamed: 0')\n",
    "\n",
    "\n",
    "# helper function to find total passengers per airport\n",
    "def make_df(df,year):\n",
    "    \n",
    "    '''\n",
    "    Returns a list of DataFrames ordered by month\n",
    "    showing the total passenger counts for the corresponding aiport\n",
    "    \n",
    "    \n",
    "    Arguments:\n",
    "    df -- DataFrame from passengers table\n",
    "            - must include 'passengers', 'month', 'year', \n",
    "              and 'origin_airport_id' features\n",
    "    year -- 2018 or 2019\n",
    "            \n",
    "    Returns:\n",
    "    List of DataFrames\n",
    "        - Columns: total passengers, month, year\n",
    "        - Row: origin_airport_ids\n",
    "    '''\n",
    "    \n",
    "    months = [1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "    year = year\n",
    "    dfs = []\n",
    "    \n",
    "    for month in months:\n",
    "        X = df.loc[(df.month == month) & (df.year == year)].groupby('origin_airport_id')[['passengers']].sum()\n",
    "        X['month'] = month\n",
    "        X['year'] = year\n",
    "        dfs.append(X)\n",
    "        \n",
    "    return dfs\n",
    "\n",
    "\n",
    "# use function to find passenger counts for 2018 and 2019\n",
    "passengers_per_month_2018 = make_df(pas_df, 2018)\n",
    "passengers_per_month_2019 = make_df(pas_df, 2019)\n",
    "\n",
    "\n",
    "# take list of DataFrames and concatenate \n",
    "pass_2018 = pd.concat(passengers_per_month_2018)\n",
    "pass_2019 = pd.concat(passengers_per_month_2019)\n",
    "\n",
    "\n",
    "# merge yearly DataFrames\n",
    "avg_monthly_pas = pd.merge(pass_2018, pass_2019, how='left', on=['origin_airport_id', 'month'])\n",
    "\n",
    "\n",
    "# fill NaN values \n",
    "avg_monthly_pas.passengers_y.fillna(avg_monthly_pas.passengers_x, inplace=True)\n",
    "avg_monthly_pas.year_y.fillna(avg_monthly_pas.year_x + 1, inplace=True)\n",
    "\n",
    "\n",
    "# calculate an average monthly passenger feature for each airport\n",
    "avg_monthly_pas['avg_monthly_pas'] = (avg_monthly_pas.passengers_x + avg_monthly_pas.passengers_y) / 2\n",
    "\n",
    "\n",
    "# drop unnecessary features\n",
    "avg_monthly_pas = avg_monthly_pas[['month','avg_monthly_pas']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save feature to csv\n",
    "avg_monthly_pas.to_csv('avg_monthly_pas.csv', index='origin_airport_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge onto training DataFrame\n",
    "final = pd.merge(X, avg_monthly_pas, how='left', on=['origin_airport_id','month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = final.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mkt_carrier_fl_num</th>\n",
       "      <th>origin_airport_id</th>\n",
       "      <th>dest_airport_id</th>\n",
       "      <th>crs_dep_time</th>\n",
       "      <th>crs_arr_time</th>\n",
       "      <th>crs_elapsed_time</th>\n",
       "      <th>distance</th>\n",
       "      <th>mkt_unique_carrier</th>\n",
       "      <th>tail_num</th>\n",
       "      <th>branded_code_share</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>week</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>avg_monthly_pas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3501</td>\n",
       "      <td>12953</td>\n",
       "      <td>13930</td>\n",
       "      <td>1300</td>\n",
       "      <td>1444</td>\n",
       "      <td>164.0</td>\n",
       "      <td>733.0</td>\n",
       "      <td>UA</td>\n",
       "      <td>N744YX</td>\n",
       "      <td>UA_CODESHARE</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>66470.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3502</td>\n",
       "      <td>11433</td>\n",
       "      <td>12266</td>\n",
       "      <td>630</td>\n",
       "      <td>854</td>\n",
       "      <td>204.0</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>UA</td>\n",
       "      <td>N640RW</td>\n",
       "      <td>UA_CODESHARE</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>108812.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3503</td>\n",
       "      <td>11618</td>\n",
       "      <td>11433</td>\n",
       "      <td>1500</td>\n",
       "      <td>1709</td>\n",
       "      <td>129.0</td>\n",
       "      <td>488.0</td>\n",
       "      <td>UA</td>\n",
       "      <td>N641RW</td>\n",
       "      <td>UA_CODESHARE</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>94693.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3504</td>\n",
       "      <td>11618</td>\n",
       "      <td>11278</td>\n",
       "      <td>2041</td>\n",
       "      <td>2159</td>\n",
       "      <td>78.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>UA</td>\n",
       "      <td>N722YX</td>\n",
       "      <td>UA_CODESHARE</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>94693.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3505</td>\n",
       "      <td>12266</td>\n",
       "      <td>11298</td>\n",
       "      <td>2140</td>\n",
       "      <td>2257</td>\n",
       "      <td>77.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>UA</td>\n",
       "      <td>N855RW</td>\n",
       "      <td>UA_CODESHARE</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155988.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161997</th>\n",
       "      <td>2789</td>\n",
       "      <td>13487</td>\n",
       "      <td>14771</td>\n",
       "      <td>925</td>\n",
       "      <td>1143</td>\n",
       "      <td>258.0</td>\n",
       "      <td>1589.0</td>\n",
       "      <td>DL</td>\n",
       "      <td>N886DN</td>\n",
       "      <td>DL</td>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>136111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161998</th>\n",
       "      <td>2790</td>\n",
       "      <td>10721</td>\n",
       "      <td>13487</td>\n",
       "      <td>1841</td>\n",
       "      <td>2101</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>DL</td>\n",
       "      <td>N302DN</td>\n",
       "      <td>DL</td>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>84468.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161999</th>\n",
       "      <td>2791</td>\n",
       "      <td>10397</td>\n",
       "      <td>11298</td>\n",
       "      <td>1000</td>\n",
       "      <td>1116</td>\n",
       "      <td>136.0</td>\n",
       "      <td>731.0</td>\n",
       "      <td>DL</td>\n",
       "      <td>N375NC</td>\n",
       "      <td>DL</td>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>379869.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162000</th>\n",
       "      <td>2791</td>\n",
       "      <td>11298</td>\n",
       "      <td>10397</td>\n",
       "      <td>1201</td>\n",
       "      <td>1512</td>\n",
       "      <td>131.0</td>\n",
       "      <td>731.0</td>\n",
       "      <td>DL</td>\n",
       "      <td>N375NC</td>\n",
       "      <td>DL</td>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>262691.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162001</th>\n",
       "      <td>2793</td>\n",
       "      <td>12889</td>\n",
       "      <td>14747</td>\n",
       "      <td>1855</td>\n",
       "      <td>2132</td>\n",
       "      <td>157.0</td>\n",
       "      <td>867.0</td>\n",
       "      <td>DL</td>\n",
       "      <td>N3756</td>\n",
       "      <td>DL</td>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>170187.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156746 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        mkt_carrier_fl_num  origin_airport_id  dest_airport_id  crs_dep_time  \\\n",
       "0                     3501              12953            13930          1300   \n",
       "1                     3502              11433            12266           630   \n",
       "2                     3503              11618            11433          1500   \n",
       "3                     3504              11618            11278          2041   \n",
       "4                     3505              12266            11298          2140   \n",
       "...                    ...                ...              ...           ...   \n",
       "161997                2789              13487            14771           925   \n",
       "161998                2790              10721            13487          1841   \n",
       "161999                2791              10397            11298          1000   \n",
       "162000                2791              11298            10397          1201   \n",
       "162001                2793              12889            14747          1855   \n",
       "\n",
       "        crs_arr_time  crs_elapsed_time  distance mkt_unique_carrier tail_num  \\\n",
       "0               1444             164.0     733.0                 UA   N744YX   \n",
       "1                854             204.0    1075.0                 UA   N640RW   \n",
       "2               1709             129.0     488.0                 UA   N641RW   \n",
       "3               2159              78.0     199.0                 UA   N722YX   \n",
       "4               2257              77.0     224.0                 UA   N855RW   \n",
       "...              ...               ...       ...                ...      ...   \n",
       "161997          1143             258.0    1589.0                 DL   N886DN   \n",
       "161998          2101             200.0    1124.0                 DL   N302DN   \n",
       "161999          1116             136.0     731.0                 DL   N375NC   \n",
       "162000          1512             131.0     731.0                 DL   N375NC   \n",
       "162001          2132             157.0     867.0                 DL    N3756   \n",
       "\n",
       "       branded_code_share  year  month  week  day  day_of_week  \\\n",
       "0            UA_CODESHARE  2018      1     1    1            0   \n",
       "1            UA_CODESHARE  2018      1     1    1            0   \n",
       "2            UA_CODESHARE  2018      1     1    1            0   \n",
       "3            UA_CODESHARE  2018      1     1    1            0   \n",
       "4            UA_CODESHARE  2018      1     1    1            0   \n",
       "...                   ...   ...    ...   ...  ...          ...   \n",
       "161997                 DL  2019      7    31   31            2   \n",
       "161998                 DL  2019      7    31   31            2   \n",
       "161999                 DL  2019      7    31   31            2   \n",
       "162000                 DL  2019      7    31   31            2   \n",
       "162001                 DL  2019      7    31   31            2   \n",
       "\n",
       "        avg_monthly_pas  \n",
       "0               66470.5  \n",
       "1              108812.5  \n",
       "2               94693.5  \n",
       "3               94693.5  \n",
       "4              155988.0  \n",
       "...                 ...  \n",
       "161997         136111.0  \n",
       "161998          84468.5  \n",
       "161999         379869.5  \n",
       "162000         262691.5  \n",
       "162001         170187.0  \n",
       "\n",
       "[156746 rows x 16 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature engineering will play a crucial role in this problems. We have only very little attributes so we need to create some features that will have some predictive power.\n",
    "\n",
    "- weather: we can use some weather API to look for the weather in time of the scheduled departure and scheduled arrival.\n",
    "- statistics (avg, mean, median, std, min, max...): we can take a look at previous delays and compute descriptive statistics\n",
    "- airports encoding: we need to think about what to do with the airports and other categorical variables\n",
    "- time of the day: the delay probably depends on the airport traffic which varies during the day.\n",
    "- airport traffic\n",
    "- unsupervised learning as feature engineering?\n",
    "- **what are the additional options?**: Think about what we could do more to improve the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection / Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to apply different selection techniques to find out which one will be the best for our problems.\n",
    "\n",
    "- Original Features vs. PCA conponents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use different ML techniques to predict each problem.\n",
    "\n",
    "- linear / logistic / multinomial logistic regression\n",
    "- Naive Bayes\n",
    "- Random Forest\n",
    "- SVM\n",
    "- XGBoost\n",
    "- The ensemble of your own choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have data from 2018 and 2019 to develop models. Use different evaluation metrics for each problem and compare the performance of different models.\n",
    "\n",
    "You are required to predict delays on **out of sample** data from **first 7 days (1st-7th) of January 2020** and to share the file with LighthouseLabs. Sample submission can be found in the file **_sample_submission.csv_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "======================================================================\n",
    "## Stretch Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiclass Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variables are **CARRIER_DELAY, WEATHER_DELAY, NAS_DELAY, SECURITY_DELAY, LATE_AIRCRAFT_DELAY**. We need to do additional transformations because these variables are not binary but continuos. For each flight that was delayed, we need to have one of these variables as 1 and others 0.\n",
    "\n",
    "It can happen that we have two types of delays with more than 0 minutes. In this case, take the bigger one as 1 and others as 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variable is **CANCELLED**. The main problem here is going to be huge class imbalance. We have only very little cancelled flights with comparison to all flights. It is important to do the right sampling before training and to choose correct evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
